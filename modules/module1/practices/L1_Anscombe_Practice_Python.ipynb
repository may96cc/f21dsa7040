{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1 Python Practice: Anscombe's Quartet\n",
    "\n",
    "In this practice, we will recreate the Anscombe's Quartet visualization in Python similar to how we have done it in R. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"../images/AnscombeStats.png\">\n",
    "\n",
    "<img src=\"../images/AnscombeGraph.png\">\n",
    "\n",
    "**We will use the `plotnine` library which is a good implementation of `ggplot2` in Python.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import *\n",
    "import pandas as pd\n",
    "\n",
    "#read the anscombe dataset\n",
    "anscombe = pd.read_csv(\"/dsa/data/all_datasets/anscombe.csv\")\n",
    "\n",
    "# the same data set also comes with the seaborn library, we can just load it to the workspace\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "anscombe2 = sns.load_dataset('anscombe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at the data itself\n",
    "anscombe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns version is slightly different \n",
    "anscombe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's look at the statistics: we can utilize the `dataset` column in the sns version\n",
    "grouped = anscombe2.groupby('dataset')\n",
    "grouped.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation\n",
    "grouped.apply(lambda df: df['x'].corr(df['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance\n",
    "grouped['y'].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression (first pair)\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "group1 = grouped.get_group('I')\n",
    "x = group1['x'].values\n",
    "y = group1['y'].values\n",
    "slope, intercept, _,_,_ = stats.linregress(x, y)\n",
    "print(\"dataset I slope: {:.4f}, intercept: {:.4f}\".format(slope, intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression (second pair)\n",
    "group1 = grouped.get_group('II')\n",
    "x = group1['x'].values\n",
    "y = group1['y'].values\n",
    "slope, intercept, _,_,_ = stats.linregress(x, y)\n",
    "print(\"dataset II slope: {:.4f}, intercept: {:.4f}\".format(slope, intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, it's your turn: Find the linear regression coefficients for the next two data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression (next two pairs)\n",
    "# <your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's do the same plots as in the R practice notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = ggplot(anscombe,aes(x=\"x1\", y=\"y1\"))\n",
    "p1 = p1 + geom_point()\n",
    "p1 = p1 + stat_smooth(method= 'lm', se=False) + expand_limits(x=4, y=4)\n",
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the version with similar visuals as in the original plot from the lab notebook:\n",
    "pp1 = ggplot(anscombe) + geom_point(aes(x=\"x1\",y= \"y1\"), color = \"darkorange\")\n",
    "pp1 = pp1 + theme_bw() + scale_x_continuous(breaks = range(0,18,2))\n",
    "pp1 = pp1 + scale_y_continuous(breaks = range(0, 12, 2))\n",
    "pp1 = pp1 + geom_abline(intercept = 3, slope = 0.5, color = \"cornflowerblue\")\n",
    "pp1 = pp1 + expand_limits(x=[4,18], y=[4,12])\n",
    "pp1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we do not have the gridding library in Python, we can use the `facet_wrap()` function utilizing the dataset column of the sns version of the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp12 = (ggplot(anscombe2, aes('x', 'y'))\n",
    " + geom_point()\n",
    " + stat_smooth(method='lm', se=False, color='blue',size=0.5)\n",
    " + facet_wrap('~dataset'))\n",
    "\n",
    "pp12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the original look: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(anscombe2, aes('x', 'y'))\n",
    " + geom_point(color='darkorange')\n",
    " + theme_bw()\n",
    " + scale_y_continuous(breaks=[y for y in range(0,13,2)])\n",
    " + scale_x_continuous(breaks=[x for x in range(0,19,2)])\n",
    " + stat_smooth(method='lm', se=False, color='blue',size=0.5)\n",
    " + facet_wrap('~dataset'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
